\chapter{Background Theory}

\section{Introduction to Computer Vision}

\subsection{Introduction}
nanana

\subsection{How it's Done}
nanana

\subsection{OpenCV}

OpenCV started... 1999 Intel. Today, it is a fully open source library with a vast number of advanced computer vision algorithms. The pre-build library can quickly be plugged into  an IDE such as Qt Creator or Visual Studio 2013 (not tested for compatibility with Visual Studio 2015 at the time of writing), thus giving the programmer access to all basic OpenCV features. A steb-by-step guide for using both the pre-built and a custom-built library can be found in Appendix \ref{}.

\section{Stereo Vision and Depth Perception}

Stereo vision and depth perception is one of the core topics within this report. Here, the theory behind a method using two cameras is presented, while some additional methods are mentioned to provide context.

Methods for computer vision can be separated into two main categories, i.e. active and passive. Active sensors will usually project a light pattern onto the scene to be perceived, before sensing how this pattern is displaced by the topology of the scene. The Kinect sensor and 3d-scanners using laser light are typical examples of active sensors. Passive depth perception makes use of many of the same cues we use to perceive depth. The most common passive sensors extract the depth information by observing observing a scene from at least two different positions. 

Optical flow is another important method for depth perception. Optical flow may be either active or passive. The passive variant requires  only one camera, but depends on motion and a stream of images to extract depth information. Observing how much some chosen features in a scene has moved in the image frame at $t = 1$ compared to the frame at $t = 0$ is the basis of depth sensing from optical flow. In a static scene, objects that are far away will naturally have an optical flow field with a smaller magnitude than objects that are close. 

In this project, passive stereoscopic vision is achieved by using two identical (in theory) cameras placed on the same plane. The cameras are placed a few centimetres apart. This distance is called the baseline $B$. The gist of this method is based on the fact that objects close to the cameras will have a large displacement from the left to the right camera compared to objects that are further away. 
